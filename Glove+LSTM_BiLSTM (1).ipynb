{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Glove+LSTM/BiLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WigneUJ7g2J"
      },
      "source": [
        "# **GLoVE+BiLSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBLGq3tsHaZK",
        "outputId": "af3b04e7-afca-4cc4-f945-6190ee54f6a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install keras\n",
        "!pip install emoji --upgrade\n",
        "!pip install keras-self-attention\n",
        "!pip install wordninja"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n",
            "Requirement already up-to-date: emoji in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: keras-self-attention in /usr/local/lib/python3.6/dist-packages (0.47.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (1.18.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (2.4.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras->keras-self-attention) (1.15.0)\n",
            "Requirement already satisfied: wordninja in /usr/local/lib/python3.6/dist-packages (2.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaDxi6vN8yil"
      },
      "source": [
        "# **Headers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcKlqkNXGbut"
      },
      "source": [
        "##################Headers#########\n",
        "import pandas as pd\n",
        "import keras\n",
        "import emoji\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers, regularizers, constraints\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Embedding, Input\n",
        "from keras.layers import LSTM, Bidirectional, Dropout\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnECRf1Y89QB"
      },
      "source": [
        "# **Loading the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r5Wv9y0Gtcm",
        "outputId": "a82177ea-4b7a-4b88-e8df-1140166e0efa",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d2659f7b-685f-492f-a881-7db811c74bc1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d2659f7b-685f-492f-a881-7db811c74bc1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving ISEAR.csv to ISEAR (2).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCxGj6cqoEZe"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"ISEAR.csv\",names=[\"emotion\",\"text\",\"\"])\n",
        "df=df[[\"text\",\"emotion\"]]\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "df_train,df_test=train_test_split(df, test_size=0.25, random_state=42, stratify=df[\"emotion\"])"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGzwdGXFAiOS",
        "outputId": "841de8fc-ed5e-4afa-bf6a-f433e9c7693a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df_test"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>824</th>\n",
              "      <td>Being slandered by friends.</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>590</th>\n",
              "      <td>I said nasty things which I did not mean to a ...</td>\n",
              "      <td>guilt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2992</th>\n",
              "      <td>I felt it when I came home after the examinati...</td>\n",
              "      <td>guilt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3095</th>\n",
              "      <td>I was disgusted by my paranoid attitude toward...</td>\n",
              "      <td>disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3279</th>\n",
              "      <td>As a result of breaking the indicator light as...</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2516</th>\n",
              "      <td>When I thought for an instant that a very good...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1387</th>\n",
              "      <td>When the grandmother of my friend died in a ho...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2618</th>\n",
              "      <td>I didn't do an important job and it had an adv...</td>\n",
              "      <td>shame</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>800</th>\n",
              "      <td>The negative feelings towards me displayed by ...</td>\n",
              "      <td>guilt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>My girlfriend gave me the mitten (left me).</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1879 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  emotion\n",
              "824                         Being slandered by friends.    anger\n",
              "590   I said nasty things which I did not mean to a ...    guilt\n",
              "2992  I felt it when I came home after the examinati...    guilt\n",
              "3095  I was disgusted by my paranoid attitude toward...  disgust\n",
              "3279  As a result of breaking the indicator light as...     fear\n",
              "...                                                 ...      ...\n",
              "2516  When I thought for an instant that a very good...  sadness\n",
              "1387  When the grandmother of my friend died in a ho...  sadness\n",
              "2618  I didn't do an important job and it had an adv...    shame\n",
              "800   The negative feelings towards me displayed by ...    guilt\n",
              "997         My girlfriend gave me the mitten (left me).  sadness\n",
              "\n",
              "[1879 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3_81hGVHZ41",
        "outputId": "33384339-0fd6-4ebe-8aa0-d81fcaaf0fe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "classes_list = df_train.emotion.unique().tolist()\n",
        "df_train[\"class\"]=df_train['emotion'].apply(classes_list.index)\n",
        "df_test[\"class\"]=df_test['emotion'].apply(classes_list.index)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV8812OU9GaD"
      },
      "source": [
        "# ***Preprocessing Functions***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI4fxCud9moQ"
      },
      "source": [
        "Expanding Contractions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klvUPYGNvcOW"
      },
      "source": [
        "import re\n",
        "#########Contraction List#####\n",
        "cList = {\"ain't\": \"am not\",\"aren't\": \"are not\",\"can't\": \"cannot\",\"can't've\": \"cannot have\",\"'cause\": \"because\",\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\"couldn't've\": \"could not have\",\"didn't\": \"did not\",\"doesn't\": \"does not\",\"don't\": \"do not\",\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\"he'd've\": \"he would have\",\"he'll\": \"he will\",\"he'll've\": \"he will have\",\n",
        "\"he's\": \"he is\",\"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\"how's\": \"how is\",\"I'd\": \"I would\",\"I'd've\": \"I would have\",\n",
        "\"I'll\": \"I will\",\"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\",\"isn't\": \"is not\",\"it'd\": \"it had\",\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it will\",\"it'll've\": \"it will have\",\"it's\": \"it is\",\"let's\": \"let us\",\"ma'am\": \"madam\",\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\"needn't\": \"need not\",\"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\"shan't've\": \"shall not have\",\"she'd\": \"she would\",\n",
        "\"she'd've\": \"she would have\",\"she'll\": \"she will\",\"she'll've\": \"she will have\",\"she's\": \"she is\",\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\"shouldn't've\": \"should not have\",\"so've\": \"so have\",\"so's\": \"so is\",\"that'd\": \"that would\",\n",
        "\"that'd've\": \"that would have\",\"that's\": \"that is\",\"there'd\": \"there had\",\"there'd've\": \"there would have\",\"there's\": \"there is\",\n",
        "\"they'd\": \"they would\",\"they'd've\": \"they would have\",\"they'll\": \"they will\",\"they'll've\": \"they will have\",\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we had\",\"we'd've\": \"we would have\",\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\"we're\": \"we are\",\"we've\": \"we have\",\"weren't\": \"were not\",\"what'll\": \"what will\",\"what'll've\": \"what will have\",\n",
        "\"what're\": \"what are\",\"what's\": \"what is\",\"what've\": \"what have\",\"when's\": \"when is\",\"when've\": \"when have\",\"where'd\": \"where did\",\n",
        "\"where's\": \"where is\",\"where've\": \"where have\",\"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who's\": \"who is\",\"who've\": \"who have\",\n",
        "\"why's\": \"why is\",\"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\"won't've\": \"will not have\",\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\"wouldn't've\": \"would not have\",\"y'all\": \"you all\",\"y'alls\": \"you alls\",\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you had\",\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you you will\",\"you'll've\": \"you you will have\",\"you're\": \"you are\",\"you've\": \"you have\"}\n",
        "#########Function for contraction#####\n",
        "c_re = re.compile('(%s)' % '|'.join(cList.keys())) #regular expression object, with format of contractions like i'm, i've\n",
        "def expandContractions(text, c_re=c_re):\n",
        "    def replace(match):\n",
        "        return cList[match.group(0)] #find the match in the list\n",
        "    return c_re.sub(replace, text)  #replacing the short hands with expanded version"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNIcTaiy91Kq"
      },
      "source": [
        "Lemmatization according to sentence structure "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Maa-nAu97qF",
        "outputId": "f787889d-b3bf-4c75-a85c-747e56852664",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb0sMADs8Qi2"
      },
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import stopwords\n",
        "tag_map = defaultdict(lambda : wn.NOUN)\n",
        "tag_map['J'] = wn.ADJ\n",
        "tag_map['V'] = wn.VERB\n",
        "tag_map['R'] = wn.ADV\n",
        "lemma_function = WordNetLemmatizer()\n",
        "def lemmatize(row):\n",
        "  tokens = word_tokenize(row)\n",
        "  new =  \"\"\n",
        "  for token, tag in pos_tag(tokens):\n",
        "    if token not in stopwords.words('english'):\n",
        "      lemma = lemma_function.lemmatize(token, tag_map[tag[0]])\n",
        "      new=new+lemma+\" \"\n",
        "  return new"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I75gg3gwo8qh",
        "outputId": "b484b806-9903-4ac0-b29c-f5ccc6eddb61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPfEpo8v9_lA"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "491detyu-lD2",
        "outputId": "50c8310f-9223-4737-b231-36755d5ed0f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from nltk.corpus import stopwords\n",
        "df_train[\"text\"]=df_train[\"text\"].str.replace(\"@\",\"username\") #removing @\n",
        "df_train[\"text\"]=df_train[\"text\"].str.replace(\"'s\",\"\")\n",
        "df_train[\"text\"]=df_train[\"text\"].str.replace(\"?\",\" question \")\n",
        "df_train[\"text\"]=df_train[\"text\"].str.replace(\"!\",\" exclamation \")\n",
        "df_train[\"text\"]=df_train[\"text\"].str.replace(r'http\\S+', '')# removing links\n",
        "df_train[\"text\"]=df_train[\"text\"].apply(expandContractions) #expanding contractions\n",
        "df_train[\"text\"]=df_train[\"text\"].apply(emoji.demojize)#changing emojis to text\n",
        "df_train[\"text\"]=df_train[\"text\"].str.replace(\"#\",\"\").str.replace(\"_\",\" \").str.replace(\":\",\" \").str.lower()\n",
        "df_train[\"text\"]=df_train[\"text\"].apply(lemmatize) #lemmatization\n",
        "df_train[\"text\"]=df_train[\"text\"].str.replace(r'[^\\w\\s]',\" \") #removing punctuation\n",
        "df_test[\"text\"]=df_test[\"text\"].str.replace(\"@\",\"username\")\n",
        "df_test[\"text\"]=df_test[\"text\"].str.replace(\"'s\",\"\")\n",
        "df_test[\"text\"]=df_test[\"text\"].str.replace(\"?\",\" question \")\n",
        "df_test[\"text\"]=df_test[\"text\"].str.replace(\"!\",\" exclamation \")\n",
        "df_test[\"text\"]=df_test[\"text\"].str.replace(r'http\\S+', '')\n",
        "df_test[\"text\"]=df_test[\"text\"].apply(expandContractions)\n",
        "df_test[\"text\"]=df_test[\"text\"].apply(emoji.demojize)\n",
        "df_test[\"text\"]=df_test[\"text\"].str.replace(\"#\",\"\").str.replace(\"_\",\" \").str.replace(\":\",\"\").str.lower()\n",
        "df_test[\"text\"]=df_test[\"text\"].apply(lemmatize)\n",
        "df_test[\"text\"]=df_test[\"text\"].str.replace(r'[^\\w\\s]',\"\")\n",
        "tokenizer = Tokenizer(num_words=5000) # tokenizing\n",
        "tokenizer.fit_on_texts(df_train[\"text\"].values.tolist())\n",
        "#Creating the training and testing sets consisting of tokens\n",
        "X_train = tokenizer.texts_to_sequences(df_train[\"text\"].values.tolist())\n",
        "X_test = tokenizer.texts_to_sequences(df_test[\"text\"].values.tolist())\n",
        "vocab_size = len(tokenizer.word_index) + 1 \n",
        "word_index=tokenizer.word_index"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJZ_S138dfF1",
        "outputId": "b766874c-3fa1-4dcd-9bd8-22b8f2b4aa32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(word_index)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6260"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQCfykSh_QRt"
      },
      "source": [
        "Preparing the training and testing sets for Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhzvBMmtKV4U"
      },
      "source": [
        "maxlen=max([len(a) for a in X_train])"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_OppxtnV0iI"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyZP2TN8L0bI"
      },
      "source": [
        "y_train=df_train[\"class\"].values.tolist()"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhBYHZul-05p"
      },
      "source": [
        "# **Function for Embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEMjJ8TcSxpv"
      },
      "source": [
        "import numpy as np\n",
        "def make_glovevec(glovepath, max_features, embed_size, word_index, veclen=300):\n",
        "    embeddings_index = {}\n",
        "    f = open(glovepath)\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        dimension=len(values)-1\n",
        "        word = ' '.join(values[:-300])\n",
        "        coefs = np.asarray(values[-300:], dtype='float32')\n",
        "        embeddings_index[word] = coefs.reshape(-1)\n",
        "    f.close()\n",
        "\n",
        "    nb_words = min(max_features, len(word_index)+1)\n",
        "    embedding_matrix = np.zeros((nb_words, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_features:\n",
        "            continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gRAxVSSaSC2",
        "outputId": "355876bf-2261-48b3-b8b1-bd6180d90390",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEKYaseJaLm9"
      },
      "source": [
        "max_features=len(word_index)\n",
        "embed_size=300\n",
        "embedding_vector = make_glovevec(\"/content/drive/My Drive/glove.840B.300d.txt\", max_features+1, embed_size, word_index)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO6upg0n_fIK"
      },
      "source": [
        "# The Classifiers "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0UksjuIcR5F"
      },
      "source": [
        " ############### Keras\n",
        "from keras.models import Sequential\n",
        "from keras_self_attention import SeqSelfAttention as Attention\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPwYa0d9hHVi",
        "outputId": "439a47cb-dc7c-4f14-a957-9f6de39d15f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.unique(y_train)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibQCjPwtn6NB"
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "#################BiLSTM Attention+ Relu without any dropouts ######################\n",
        "def make_model():\n",
        "  d2=0.0\n",
        "  d1=0.0\n",
        "  #class_weight=class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)\n",
        "  model_glove = Sequential()\n",
        "  model_glove.add(Embedding(len(word_index)+1, 300, input_length=78, weights=[embedding_vector], trainable=False))\n",
        "  model_glove.add(Bidirectional(LSTM(300, return_sequences=True, dropout=d1,recurrent_dropout=d2)))\n",
        "  #model_glove.add(Attention(attention_activation='sigmoid'))\n",
        "  #model_glove.add(Flatten())\n",
        "  model_glove.add(Dense(10, activation='relu'))\n",
        "  model_glove.add(Flatten())\n",
        "  #model_glove.add(Dropout(0.0)) \n",
        "  model_glove.add(Dense(7, activation='softmax'))\n",
        "  #model_glove.add(Flatten())\n",
        "  return model_glove"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o17JSTr4P2yR"
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "#################BiLSTM Attention+ Relu without any dropouts ######################\n",
        "def make_model_lstm():\n",
        "  d2=0.0\n",
        "  d1=0.0\n",
        "  #class_weight=class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)\n",
        "  model_glove = Sequential()\n",
        "  model_glove.add(Embedding(len(word_index)+1, 300, input_length=78, weights=[embedding_vector], trainable=False))\n",
        "  model_glove.add(Bidirectional(LSTM(300, return_sequences=True, dropout=d1,recurrent_dropout=d2)))\n",
        "  #model_glove.add(Attention(attention_activation='sigmoid'))\n",
        "  #model_glove.add(Flatten())\n",
        "  model_glove.add(Dense(10, activation='relu'))\n",
        "  model_glove.add(Flatten())\n",
        "  #model_glove.add(Dropout(0.0)) \n",
        "  model_glove.add(Dense(7, activation='softmax'))\n",
        "  #model_glove.add(Flatten())\n",
        "  return model_glove"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQWvlGhHlAMb"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "#resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "#tf.config.experimental_connect_to_host(resolver.master())\n",
        "#tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "#strategy = tf.distribute.experimental.TPUStrategy(resolver)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf1ugRHrnEPL",
        "outputId": "01a9c71e-59ec-47cc-a79a-ee1ab3c48b98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "\n",
        "strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  ['10.121.28.138:8470']\n",
            "WARNING:tensorflow:TPU system grpc://10.121.28.138:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.121.28.138:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.121.28.138:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.121.28.138:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "REPLICAS:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSyjXzBHlL4n",
        "outputId": "c4226455-c9dd-40f8-8ed3-088824836db8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "with strategy.scope():\n",
        "  model_glove=make_model()\n",
        "  opt = keras.optimizers.Adam(learning_rate=0.00001)\n",
        "  model_glove.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "model_glove.summary()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 78, 300)           1878300   \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 78, 600)           1442400   \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 78, 10)            6010      \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 780)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 7)                 5467      \n",
            "=================================================================\n",
            "Total params: 3,332,177\n",
            "Trainable params: 1,453,877\n",
            "Non-trainable params: 1,878,300\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-zyn5-gotMm",
        "outputId": "02918dee-2733-4d3b-bc24-43b5d4c3ab66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y_binary = to_categorical(y_train)\n",
        "model_glove.fit(X_train, y_binary, epochs =15)#,class_weight = class_weight)#,sample_weight=sample_weight)\n",
        "model_glove.summary()\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "  1/177 [..............................] - ETA: 4:15 - loss: 1.9477 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_train_batch_end` time: 0.0244s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_train_batch_end` time: 0.0244s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "177/177 [==============================] - 7s 40ms/step - loss: 1.9408 - accuracy: 0.1689\n",
            "Epoch 2/15\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 1.9258 - accuracy: 0.2395\n",
            "Epoch 3/15\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 1.9057 - accuracy: 0.3120\n",
            "Epoch 4/15\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 1.8692 - accuracy: 0.3472\n",
            "Epoch 5/15\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 1.7927 - accuracy: 0.3502\n",
            "Epoch 6/15\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 1.7119 - accuracy: 0.3404\n",
            "Epoch 7/15\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 1.6658 - accuracy: 0.3507\n",
            "Epoch 8/15\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 1.6341 - accuracy: 0.3651\n",
            "Epoch 9/15\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 1.6050 - accuracy: 0.3789\n",
            "Epoch 10/15\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 1.5772 - accuracy: 0.3915\n",
            "Epoch 11/15\n",
            "177/177 [==============================] - 5s 28ms/step - loss: 1.5549 - accuracy: 0.3981\n",
            "Epoch 12/15\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 1.5314 - accuracy: 0.4123\n",
            "Epoch 13/15\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 1.5141 - accuracy: 0.4160\n",
            "Epoch 14/15\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 1.4899 - accuracy: 0.4339\n",
            "Epoch 15/15\n",
            "177/177 [==============================] - 5s 26ms/step - loss: 1.4720 - accuracy: 0.4394\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 78, 300)           1878300   \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 78, 600)           1442400   \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 78, 10)            6010      \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 780)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 7)                 5467      \n",
            "=================================================================\n",
            "Total params: 3,332,177\n",
            "Trainable params: 1,453,877\n",
            "Non-trainable params: 1,878,300\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQG0-Kq0Dceq",
        "outputId": "fe8d6561-1f7b-47fb-ef9e-a0300f9fdab6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_test=df_test[\"class\"].values.tolist()\n",
        "#y_pred= model_glove.predict_classes(X_test)\n",
        "y_pred= np.argmax(model_glove.predict(X_test),axis=-1)\n",
        "print(\"Accuracy score =\", accuracy_score(y_test, y_pred))\n",
        "print(metrics.classification_report(y_test, y_pred, target_names=classes_list))\n",
        "confusion_matrix(y_test, y_pred)   "
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score = 0.41351782863225117\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fear       0.60      0.55      0.57       269\n",
            "       anger       0.34      0.30      0.32       270\n",
            "       guilt       0.31      0.17      0.22       262\n",
            "     sadness       0.37      0.43      0.40       271\n",
            "     disgust       0.43      0.44      0.43       266\n",
            "       shame       0.31      0.25      0.28       268\n",
            "         joy       0.45      0.75      0.56       273\n",
            "\n",
            "    accuracy                           0.41      1879\n",
            "   macro avg       0.40      0.41      0.40      1879\n",
            "weighted avg       0.40      0.41      0.40      1879\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[147,  18,   9,  40,  26,   5,  24],\n",
              "       [ 23,  80,  25,  22,  48,  44,  28],\n",
              "       [ 22,  48,  45,  41,  21,  43,  42],\n",
              "       [ 11,  13,  15, 117,  15,   8,  92],\n",
              "       [ 29,  24,  11,  28, 116,  40,  18],\n",
              "       [  8,  41,  36,  32,  41,  68,  42],\n",
              "       [  6,   8,   6,  33,   3,  13, 204]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JctgaVjMQDNP",
        "outputId": "6951c6fb-9e77-4aa3-932c-82ba97ba21bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "with strategy.scope():\n",
        "  model_glove=make_model_lstm()\n",
        "  opt = keras.optimizers.Adam(learning_rate=0.00001)\n",
        "  model_glove.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "model_glove.summary()\n",
        "from keras.utils import to_categorical\n",
        "y_binary = to_categorical(y_train)\n",
        "model_glove.fit(X_train, y_binary, epochs =15)#,class_weight = class_weight)#,sample_weight=sample_weight)\n",
        "model_glove.summary()\n",
        "y_test=df_test[\"class\"].values.tolist()\n",
        "#y_pred= model_glove.predict_classes(X_test)\n",
        "y_pred= np.argmax(model_glove.predict(X_test),axis=-1)\n",
        "print(\"Accuracy score =\", accuracy_score(y_test, y_pred))\n",
        "print(metrics.classification_report(y_test, y_pred, target_names=classes_list))\n",
        "confusion_matrix(y_test, y_pred)   "
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 78, 300)           1878300   \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 78, 600)           1442400   \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 78, 10)            6010      \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 780)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 7)                 5467      \n",
            "=================================================================\n",
            "Total params: 3,332,177\n",
            "Trainable params: 1,453,877\n",
            "Non-trainable params: 1,878,300\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "  1/177 [..............................] - ETA: 4:11 - loss: 1.9472 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0269s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0269s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "177/177 [==============================] - 7s 40ms/step - loss: 1.9445 - accuracy: 0.1600\n",
            "Epoch 2/15\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 1.9362 - accuracy: 0.2113\n",
            "Epoch 3/15\n",
            "177/177 [==============================] - 5s 28ms/step - loss: 1.9222 - accuracy: 0.2143\n",
            "Epoch 4/15\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 1.8943 - accuracy: 0.2225\n",
            "Epoch 5/15\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 1.8151 - accuracy: 0.2611\n",
            "Epoch 6/15\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 1.7230 - accuracy: 0.3000\n",
            "Epoch 7/15\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 1.6842 - accuracy: 0.3168\n",
            "Epoch 8/15\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 1.6630 - accuracy: 0.3452\n",
            "Epoch 9/15\n",
            "177/177 [==============================] - 5s 28ms/step - loss: 1.6429 - accuracy: 0.3614\n",
            "Epoch 10/15\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 1.6213 - accuracy: 0.3830\n",
            "Epoch 11/15\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 1.5999 - accuracy: 0.3919\n",
            "Epoch 12/15\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 1.5753 - accuracy: 0.4077\n",
            "Epoch 13/15\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 1.5551 - accuracy: 0.4171\n",
            "Epoch 14/15\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 1.5337 - accuracy: 0.4190\n",
            "Epoch 15/15\n",
            "177/177 [==============================] - 5s 27ms/step - loss: 1.5130 - accuracy: 0.4350\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 78, 300)           1878300   \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 78, 600)           1442400   \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 78, 10)            6010      \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 780)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 7)                 5467      \n",
            "=================================================================\n",
            "Total params: 3,332,177\n",
            "Trainable params: 1,453,877\n",
            "Non-trainable params: 1,878,300\n",
            "_________________________________________________________________\n",
            "Accuracy score = 0.4065992549228313\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fear       0.54      0.38      0.44       269\n",
            "       anger       0.30      0.24      0.27       270\n",
            "       guilt       0.32      0.23      0.27       262\n",
            "     sadness       0.45      0.51      0.48       271\n",
            "     disgust       0.35      0.62      0.45       266\n",
            "       shame       0.34      0.22      0.26       268\n",
            "         joy       0.53      0.65      0.58       273\n",
            "\n",
            "    accuracy                           0.41      1879\n",
            "   macro avg       0.40      0.41      0.39      1879\n",
            "weighted avg       0.40      0.41      0.39      1879\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[101,  17,  16,  39,  62,  10,  24],\n",
              "       [ 19,  65,  28,  16,  89,  30,  23],\n",
              "       [ 21,  45,  59,  37,  53,  29,  18],\n",
              "       [ 18,  18,  17, 137,  16,  11,  54],\n",
              "       [ 14,  19,  15,  17, 166,  22,  13],\n",
              "       [ 11,  43,  28,  20,  81,  58,  27],\n",
              "       [  3,   9,  20,  39,  13,  11, 178]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwVz9jjyTyt9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}